# CRC_XAI
The repository provides code and datasets for explainability analysis of fake news and hate speech using both the SHapley Additive exPlanations (SHAP) method and the Local Interpretable Model-agnostic Explanations (LIME) method. The Jupyter Notebook files (.ipynb) in the repository provide a step-by-step guide for analyzing the models' predictions and generating explanations for them. 

The repository contains separate datasets for fake news and hate speech.

The explainability analysis aims to understand how the models make decisions and which features are most important in the prediction. This can help in identifying and mitigating the biases in the models and improving their transparency and accountability.

The SHAP and LIME methods are used in this repository as they provide complementary approaches to explain the output of any machine learning model. The SHAP method can be used to generate global interpretations of the model, while the LIME method can be used to generate local interpretations.

The repository also includes a requirements.txt file that lists the necessary packages and their versions for running the code in the repository.

Overall, this repository can be a useful resource for researchers and practitioners working on understanding and mitigating the harmful effects of fake news and hate speech in online platforms.

To install the necessary packages, clone this repositoryt and run the following command in your terminal:

```python
pip install -r requirements.txt
